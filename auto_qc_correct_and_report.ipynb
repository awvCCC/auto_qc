{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\student\\Documents\\Alistair CoAgMET Projects\\Pythonstuff\\QC\\auto_qc'\n",
    "os.chdir(path)\n",
    "\n",
    "csv = (path + r'\\csv.csv')\n",
    "txt = (path + r'\\qaqc_report.txt')\n",
    "q = open(txt,'w+')\n",
    "\n",
    "\n",
    "all_fm_data = 'tmean,rh,vp,sr,ws,wind_vec,wind_std,pp,st5,st15,gust,gusttm,gustdir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datapull(a,b,c,d,e):\n",
    "    \"\"\"\n",
    "    Returns an easy to understand dataframe which includes missing data which would\n",
    "    normally be skipped over.\n",
    "    a = Temporal frequency of data \n",
    "        -(Use 'daily' for daily data, 'hourly' for hourly data, and 'five_minute' for five minute data)\n",
    "    b = Station(s) from which you like to request data \n",
    "        -(Use the five character station ID(s) which can be found at \n",
    "        https://coagmet.colostate.edu/station_index.php)\n",
    "    c = Starting date of the time period from which you would like to request data\n",
    "        -(All dates must be entered in 'yyyy-mm-dd' format)\n",
    "    d = Ending date of the time period from which you would like to request data\n",
    "        -(All dates must be entered in 'yyyy-mm-dd' format)\n",
    "    e = Abbreviations of data elements you would like to request\n",
    "        -(Abbrevations for each element can be found at \n",
    "        https://coagmet.colostate.edu/cgi-bin/web_services.pl)\n",
    "    \n",
    "    Each of the above arguments must be entered into the function as a STRING\n",
    "    \"\"\"\n",
    "    \n",
    "    # Pulls raw data from the CoAgMET web services page and loads into a csv\n",
    "    urllib.request.urlretrieve('http://coagmet.colostate.edu/cgi-bin/web_services.pl?' +\n",
    "                              'type=' + a +\n",
    "                              '&sids=' + b +\n",
    "                              '&sdate=' + c +\n",
    "                              '&edate=' + d +\n",
    "                              '&elems=' + e,\n",
    "                              filename=csv)\n",
    "    \n",
    "    # Reads the csv into a pandas dataframe\n",
    "    data = pd.read_csv(csv)\n",
    "    # Gives the dataframe an index so that the it can be easily understood by pandas\n",
    "    data = data.reset_index()\n",
    "    \n",
    "    # Creates a list which will be used as headers from the elements string used in argument 'e'\n",
    "    headers = e.split(',')\n",
    "    # Inserts a 'date' value into the first position in the list\n",
    "    headers.insert(0,'date')\n",
    "    # Inserts a 'station' value into the first postion in the list, \n",
    "    # moving the 'date' value over to the second position\n",
    "    headers.insert(0,'station')\n",
    "    \n",
    "    # Tells pandas to used the above created list as header values for each column of the dataframe\n",
    "    data.columns = headers\n",
    "    \n",
    "    # Tells the pandas to recognize values in the 'date' column as a datetime index\n",
    "    data['date'] = pd.to_datetime(data.date)\n",
    "    \n",
    "    # Creates a new datetime index conditional upon the temporal type requested. This index will be\n",
    "    # compared against the index provided by CoAgMET web services to identify and fill any missing\n",
    "    # values that have been entirely skipped over by said web services\n",
    "    if a == 'hourly':\n",
    "        r = pd.date_range(start=c,end=d,freq='H')\n",
    "    elif a == 'five_minute':\n",
    "        r = pd.date_range(start=c,end=d,freq='5min')\n",
    "    elif a == 'daily':\n",
    "        r = pd.date_range(start=c,end=d,freq='D')\n",
    "    \n",
    "    # Creates spacing for data that was missing from the dataframe and also skipped over by the\n",
    "    # web services request. All missing data will by filled in the value np.NaN\n",
    "    data = data.set_index('date').reindex(r,copy=False).rename_axis('date')\n",
    "    \n",
    "    # Finds and reports data errors to a text file\n",
    "    g.write('QC report for whatever drainage basin we want!' + )\n",
    "    n = 0\n",
    "    for index,rows in data.iterrows():\n",
    "        if(pd.isnull(data['tmean'][n])):\n",
    "            g.write(str(data['station'][n]) + \n",
    "                    ' is missing temperature data at ' + str(data['date'][n]))\n",
    "        elif(pd.isnull(data['rh'][n])):\n",
    "            g.write(str(data['station'][n]) + \n",
    "                    ' is missing relative humidity data at ' + str(data['date'][n]))\n",
    "        elif(pd.isnull(data['vp'][n])):\n",
    "            g.write(str(data['station'][n]) + \n",
    "                    ' is missing vapor pressure data at ' + str(data['date'][n]))\n",
    "        elif(pd.isnull(data['sr'][n])):\n",
    "            g.write(str(data['station'][n]) + \n",
    "                    ' is missing solar radiation data at ' + str(data['date'][n]))\n",
    "        elif(pd.isnull(data['ws'][n])):\n",
    "    # Replaces any negative values in the gust direction column with 360Â°\n",
    "    gustdir_check = data.gustdir < 0\n",
    "    winddir_check = data.wind_vec < 0\n",
    "    \n",
    "    data.loc[gustdir_check,'gustdir'] = 360\n",
    "    data.loc[winddir_check,'wind_vec'] = 360\n",
    "    \n",
    "    # Replaces any negative solar radiation values with 0\n",
    "    sr_check = data.sr < 0\n",
    "    data.loc[sr_check,'sr'] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = datapull('five_minute','avn01','2020-01-12','2020-01-13',all_fm_data)\n",
    "df\n",
    "df.to_csv(path + r'\\before_wind_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.gustdir < 0\n",
    "column_name = 'gustdir'\n",
    "df.loc[mask,column_name] = 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path + r'\\after_wind_correct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
