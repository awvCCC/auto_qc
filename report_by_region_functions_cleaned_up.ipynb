{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "yesterday = datetime.strftime(datetime.now() - timedelta(1), '%Y-%m-%d')\n",
    "month_year = datetime.now().strftime('%b-%Y')\n",
    "z = r'C:\\Users\\awvie\\Documents'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = (r'C:\\Users\\awvie\\JupyterNotebooks\\tutorials\\scratch' + r'csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QAQC_datapull(a,b,c,d):\n",
    "    '''\n",
    "    Sends a data request to the CoAgMET server and processes the data into\n",
    "    an easy to read dataframe\n",
    "    \n",
    "    Arguments\n",
    "    - a = temporal frequency of the data \n",
    "        -must be entered as a string\n",
    "        -options:\n",
    "            -'five_minute'\n",
    "            -'hourly'\n",
    "            -'daily'\n",
    "    - b = a five character ID for one or more of the 87 CoAgMET stations\n",
    "        -must be entered as a string\n",
    "        -when calling data from multiple stations separate stations IDs\n",
    "        with a comma\n",
    "        -Station IDs can be found at https://coagmet.colostate.edu/station_index.php\n",
    "    - c = first day of the period from which you would like to request data\n",
    "        -must be entered as a string in 'yyyy-mm-dd' format\n",
    "    - d = last day of the period from which you would like to request data\n",
    "        -must be entered as a string in 'yyyy-mm-dd' format\n",
    "    '''\n",
    "    # Determines which set of elements to request depending on the data type\n",
    "    if a == 'hourly':\n",
    "        e = 'tmean,rh,vp,sr,ws,wind_vec,wind_std,pp,st5,st15,gust,gusttm,gustdir'\n",
    "        r = pd.date_range(start=c,end=d,freq='H')\n",
    "    elif a == 'five_minute':\n",
    "        e = 'tmean,rh,vp,sr,ws,wind_vec,wind_std,pp,st5,st15,gust,gusttm,gustdir'\n",
    "        r = pd.date_range(start=c,end=d,freq='5min')\n",
    "    elif a == 'daily':\n",
    "        e = ('tave,tmax,tmin,vp,rhmax,rhmin,sr,wrun,pp,' + \n",
    "        'st5mx,st5mn,st15mx,st15mn,gust,gustdir')\n",
    "        r = pd.date_range(start=c,end=d,freq='D')\n",
    "        \n",
    "    try:\n",
    "        # Makes the data request and loads the data into a csv\n",
    "        urllib.request.urlretrieve(\n",
    "            'http://coagmet.colostate.edu/cgi-bin/web_services.pl?' +\n",
    "            'type=' + a +\n",
    "            '&sids=' + b +\n",
    "            '&sdate=' + c +\n",
    "            '&edate=' + d +\n",
    "            '&elems=' + e,\n",
    "            filename=csv)\n",
    "    except Exception as e:\n",
    "        print('Something went wrong while pulling data from ' + \n",
    "              b + ': ' + e.args[0])\n",
    "    \n",
    "    \n",
    "    # Loads the data from the csv into a pandas DataFrame\n",
    "    data = pd.read_csv(csv)\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # Converts the elements string into a list so they can be used \n",
    "    # as headers in the dataframe\n",
    "    headers = e.split(',')\n",
    "    # Adds to objects to the beginning of list for columns that are added by default\n",
    "    headers.insert(0,'date')\n",
    "    headers.insert(0,'station')\n",
    "    # Assigns the objects in the list as column headers in the dataframe\n",
    "    data.columns = headers\n",
    "    \n",
    "    # Instructs the computer to recognize values in the 'date' column are timestamps\n",
    "    data['date'] = pd.to_datetime(data.date)\n",
    "    \n",
    "    # Creates a datetime index depending on the temporal frequency\n",
    "    # of the data requested\n",
    "    if a == 'hourly':\n",
    "        r = pd.date_range(start=c,end=d,freq='H')\n",
    "    elif a == 'five_minute':\n",
    "        r = pd.date_range(start=c,end=d,freq='5min')\n",
    "    elif a == 'daily':\n",
    "        r = pd.date_range(start=c,end=d,freq='D')\n",
    "    \n",
    "    # Reindexes the CoAgMET data against the newly created datetime index to\n",
    "    # make it easier to account for missing data\n",
    "    data = data.set_index('date').reindex(r,copy=False).rename_axis('date')\n",
    "\n",
    "    # Ensures that all values in the 'station' column are correct\n",
    "    data['station'] = b\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def high_report(df,element,name,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        station = str(df['station'].iloc[n])\n",
    "        datim = str(df['date'].iloc[n])\n",
    "        off_val = str(df[element].iloc[n])\n",
    "        return f.write(f'{station} reported an impossibly high {name} at {datim} : {off_val}\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def low_report(df,element,name,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        station = str(df['station'].iloc[n])\n",
    "        datim = str(df['date'].iloc[n])\n",
    "        off_val = str(df[element].iloc[n])\n",
    "        return f.write(f'{station} reported an impossibly low {name} at {datim} : {off_val}\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_report(df,name,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        station = str(df['station'].iloc[n])\n",
    "        datim = str(df['date'].iloc[n])\n",
    "        return f.write(f'{station} is missing {name} data at {datim}\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_report(df,name,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        station = str(df['station'].iloc[n])\n",
    "        datim = str(df['date'].iloc[n])\n",
    "        return f.write(f'{station} reported negative {name} at  {datim}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing_to_report(f,error_type,where):\n",
    "    if error_type == missing:\n",
    "        etype = 'missing data'\n",
    "    elif error_type == negs:\n",
    "        etype = 'negative values'\n",
    "    elif error_type == toohigh:\n",
    "        etype = 'impossibly high values'\n",
    "    elif error_type == toolow:\n",
    "        etype = 'impossibly low values'\n",
    "        \n",
    "    f.write(f'No {etype} to report of from {where}!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_accounted_for(df):\n",
    "    return len(df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_all_data(f):\n",
    "    f.write('Missing all data :(\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(x):\n",
    "    # Stores a path in which te report will be stored\n",
    "    y = x['path'] + r'\\_' + month_year\n",
    "    # Creates the pathway if it doesn't already exist\n",
    "    if not os.path.exists(y): os.makedirs(y)\n",
    "    # Creates a full name for the file that will be created    \n",
    "    file = (y + r'\\_' + yesterday + '_' + x['drainage'] + \n",
    "            '_' + x['region'] + '_QAQC_report.txt')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_check(df,element):\n",
    "    nulls = df.loc[pd.isnull(df[element])]\n",
    "    return nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_check(df,element):\n",
    "    negative = df.loc[df[element] < 0.0]\n",
    "    return negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_check(df,x,f):\n",
    "    site = df['station']\n",
    "    if x == 'tmean':\n",
    "        appelle = 'temperature'\n",
    "    elif x == 'tave':\n",
    "        appelle = 'daily average temperature'\n",
    "    elif x == 'tmax':\n",
    "        appelle = 'daily maximum temperature'\n",
    "    elif x == 'tmin':\n",
    "        appelle = 'daily minimum temperature'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        missing = missing_check(df,x)\n",
    "        toohigh = df.loc[df[x] > 46.1]\n",
    "        toolow = df.loc[df[x] < 51.6]\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toohigh) else high_report(toohigh,x,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toolow) else low_report(toolow,x,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rh_check(df,x,f):\n",
    "    if x == 'rh':\n",
    "        appelle = 'relative humidity'\n",
    "    elif x == 'rhmax':\n",
    "        appelle = 'daily max relative humidity'\n",
    "    elif x == 'rhmin':\n",
    "        appelle = 'daily min relative humidity'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        missing = missing_check(df,x)\n",
    "        toohigh = df.loc[df[x] > 1.0]\n",
    "        toolow = df.loc[df[x] < 0.01]\n",
    "        negs = neg_check(df,x)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toohigh) else high_report(toohigh,x,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toolow) else low_report(toolow,x,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_check(df,f):\n",
    "    appelle = 'solar radiation'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        neg = neg_check(df,'sr')\n",
    "        missing = missing_check(df,'sr')\n",
    "        nothing_to_report(f) if all_accounted_for(neg) else negative_report(neg,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_check(df,x,f):\n",
    "    appelle = 'wind speed'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        negs = neg_check(df,'ws')\n",
    "        missing = missing_check(df,'ws')\n",
    "        toohigh = df.loc[df['ws'] > 77.785]\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toohigh) else high_report(toohigh,x,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_check(df,f):\n",
    "    appelle = 'wind direction'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        negs = neg_check(df,'wind_vec')\n",
    "        missing = missing_check(df,'wind_vec')\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soiltemp_check(df,x,f):\n",
    "    if x == 'st5':\n",
    "        appelle = '5cm soil temp'\n",
    "    elif x == 'st15':\n",
    "        appelle = '15cm soil temp'\n",
    "    elif x == 'st5mx':\n",
    "        appelle = 'daily maximum 5cm soil temperature'\n",
    "    elif x == 'st5mn':\n",
    "        appelle = 'daily minimum 5cm soil temperature'\n",
    "    elif x == 'st15mx':\n",
    "        appelle = 'daily maximum 15cm soil temperature'\n",
    "    elif x == 'st15mn':\n",
    "        appelle = 'daily minimum 15cm soil temperature'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        toohigh = df.loc[df[x] > 50.0]\n",
    "        toolow = df.loc[df[x] > -15.0]\n",
    "        missing = missing_check(df,x)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toohigh) else high_report(toohigh,x,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toolow) else low_report(toolow,x,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gust_check(df,x,f):\n",
    "    appelle = 'gust speed'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        negs = neg_check(df,'gust')\n",
    "        missing = missing_check(df,'gust')\n",
    "        toohigh = df.loc[df['gust'] > 77.785]\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(toohigh) else high_report(toohigh,x,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_check(df,f):\n",
    "    appelle = 'precip'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        negs = neg_check(df,'pp')\n",
    "        missing = missing_check(df,'pp')\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gustdir_check(df,f):\n",
    "    appelle = 'gust direction'\n",
    "    if all_accounted_for(df):\n",
    "        missing_all_data(f)\n",
    "    else:\n",
    "        negs = neg_check(df,'gustdir')\n",
    "        missing = missing_check(df,'gustdir')\n",
    "        nothing_to_report(f) if all_accounted_for(negs) else negative_report(negs,appelle,f)\n",
    "        nothing_to_report(f) if all_accounted_for(missing) else null_report(missing,appelle,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "Collegiate_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Collegiate_Valley'),\n",
    "    'stations':'bnv01,sld01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Collegiate_Valley'\n",
    "}\n",
    "East_Valley_Bottom = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\East_Valley_Bottom'),\n",
    "    'stations':'hly01,hly02,lam01,lam03,lam04,mcl01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'East_Valley_Bottom'\n",
    "}\n",
    "Mesas = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Mesas'),\n",
    "    'stations':'cnn01,hne01,pnr01,wcf01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Mesas'\n",
    "}\n",
    "North_of_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\North_of_Valley'),\n",
    "    'stations':'scm01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Mesas'\n",
    "}\n",
    "Plateau_South_of_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Plateau_South_of_Valley'),\n",
    "    'stations':'wls01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Plateau_South_of_Valley'\n",
    "}\n",
    "West_Valley_Bottom = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\West_Valley_Bottom'),\n",
    "    'stations':'avn01,fwl01,ljt01,rfd01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'West_Valley_Bottom'\n",
    "}\n",
    "Lower_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Lower_Valley'),\n",
    "    'stations':'cbl01,slt01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Lower_Valley'\n",
    "}\n",
    "Eagle_River_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Eagle_River_Valley'),\n",
    "    'stations':'egl01,gyp01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Eagle_River_Valley'\n",
    "}\n",
    "Four_Corners = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Four_Corners'),\n",
    "    'stations':'ctz01,dvc01,mnc01,twc01,yjk01,yuc01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Four_Corners'\n",
    "}\n",
    "Grand_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Grand_Valley'),\n",
    "    'stations':'cbn01,frt03,orm02',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Grand_Valley'\n",
    "}\n",
    "Headwaters = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Headwaters'),\n",
    "    'stations':'gby01,krm01,wfd01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Headwaters'\n",
    "}\n",
    "Lower_Gunnison = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Lower_Gunnison'),\n",
    "    'stations':'dlt01,ekt01,hot02,mtr01,oth01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Lower_Gunnison'\n",
    "}\n",
    "San_Juan = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\San_Juan'),\n",
    "    'stations':'drg01,ign01,kln01,pgs01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'San Juan'\n",
    "}\n",
    "San_Miguel_Paradox = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\San_Miguel_Paradox'),\n",
    "    'stations':'brk01,nwd01',\n",
    "    'drainage':'Colorado',\n",
    "    'region': r'San_Miguel_Paradox'\n",
    "}\n",
    "Upper_Gunnison = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Upper_Gunnison'),\n",
    "    'stations':'gun01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Upper_Gunnison'\n",
    "}\n",
    "Yampa_White = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Yampa_White'),\n",
    "    'stations':'clk01,hyd01,mkr01',\n",
    "    'drainage':'Colorado',\n",
    "    'region': 'Yampa_White'\n",
    "}\n",
    "North_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Kansas_Drainage\\North_Plains'),\n",
    "    'stations':'akr02,hxt01,hyk02,ilf01,pai01,stg01,wry02,yum02',\n",
    "    'drainage':'Kansas',\n",
    "    'region':'North_Plains'\n",
    "}\n",
    "South_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Kansas_Drainage\\South_Plains'),\n",
    "    'stations':'brl02,brl03,idl01,sbt01,stn01',\n",
    "    'drainage':'Kansas',\n",
    "    'region':'South_Plains'\n",
    "}\n",
    "Front_Range_Foothills = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\Front_Range_Foothills'),\n",
    "    'stations':'ckp01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'Front_Range_Foothills'\n",
    "}\n",
    "Lower_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\Lower_Plains'),\n",
    "    'stations':'brg01,hxt01,ksy01,ksy02',\n",
    "    'drainage':'Platte',\n",
    "    'region':'Lower_Plains'\n",
    "}\n",
    "North_Front_Range = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\North_Front_Range'),\n",
    "    'stations':'alt01,fcc01,fcl01,ftc01,ftc03,gly04,lcn01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'North_Front_Range'\n",
    "}\n",
    "North_Park = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\North_Park'),\n",
    "    'stations':'cow01,heb01,lar01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'North_Park'\n",
    "}\n",
    "South_Front_Range = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\South_Front_Range'),\n",
    "    'stations':'ccr01,cht01,eac01,ftl01,lsl01,pkh01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'South_Front_Range'\n",
    "}\n",
    "South_Park = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\South_Park'),\n",
    "    'stations':'bnv01,jfn01,sld01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'South_Park'\n",
    "}\n",
    "San_Luis_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Rio_Grande_Drainage\\San_Luis_Valley'),\n",
    "    'stations':'bla01,ctr01,ctr02,ljr01,san01',\n",
    "    'drainage':'Rio_Grande',\n",
    "    'region':'San_Luis_Valley'\n",
    "}\n",
    "\n",
    "\n",
    "region_list = [Collegiate_Valley,East_Valley_Bottom,Mesas,North_of_Valley,\n",
    "               Plateau_South_of_Valley,West_Valley_Bottom,Lower_Valley,\n",
    "               Eagle_River_Valley,Four_Corners,Grand_Valley,Headwaters,\n",
    "               Lower_Gunnison,San_Juan,San_Miguel_Paradox,Upper_Gunnison,\n",
    "               Yampa_White,North_Plains,South_Plains,Front_Range_Foothills,\n",
    "               Lower_Plains,North_Front_Range,North_Park,South_Front_Range,\n",
    "               South_Park,San_Luis_Valley]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QC_report_by_region(x):\n",
    "    '''\n",
    "    Runs through the previous days data each region of the QC and reports errors \n",
    "    into a text file\n",
    "    '''\n",
    "    file = create_report(x)\n",
    "    f = open(file,'w+')\n",
    "    title = (yesterday + r' QA/QC Report for stations in the ' + x['region'] +\n",
    "            ' region of the ' + x['drainage'] + ' drainage\\n')\n",
    "    f.write(title + '\\n')\n",
    "    fmdf = pd.DataFrame()\n",
    "    station_list = x['stations'].split(',')\n",
    "    f.write('Five Minute Data\\n')\n",
    "    f.write('------------------\\n')\n",
    "    for x in station_list:\n",
    "        try:\n",
    "            fmdf = fmdf.append(QAQC_datapull('five_minute',x,yesterday,today))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all five minute data\\n')\n",
    "    fmdf = fmdf.reset_index()\n",
    "    \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "    \n",
    "    temp_check(fmdf,'tmean',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('------------------------------\\n')\n",
    "    \n",
    "    rh_check(fmdf,'rh',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    \n",
    "    sr_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    ws_check(fmdf,'ws',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    vec_check(fmdf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    \n",
    "    pp_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(fmdf,'st5',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(fmdf,'st15',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(fmdf,'gust',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    hdf = pd.DataFrame()\n",
    "    \n",
    "    f.write('Hourly Data\\n')\n",
    "    f.write('------------\\n')\n",
    "    f.write('Missing data\\n')\n",
    "    f.write('------------\\n')\n",
    "    \n",
    "    for x in station_list:\n",
    "        try:\n",
    "            hdf = hdf.append(QAQC_datapull('hourly',x,yesterday,today))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all hourly data\\n')\n",
    "    \n",
    "    hdf = hdf.reset_index()\n",
    "\n",
    "    #missing(hdf,f)\n",
    "\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "        \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "    \n",
    "    temp_check(hdf,'tmean',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('-----------------------------\\n')\n",
    "    \n",
    "    rh_check(hdf,'rh',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    sr_check(hdf,f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    ws_check(hdf,'ws',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    vec_check(hdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    pp_check(hdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(hdf,'st5',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(hdf,'st15',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(hdf,'gust',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(hdf,f)\n",
    "    \n",
    "    f.write('Daily Data\\n')\n",
    "    f.write('----------\\n')\n",
    "    f.write('Missing data:\\n')\n",
    "    f.write('-------------\\n')     \n",
    "    \n",
    "    dydf = pd.DataFrame()\n",
    "    \n",
    "    for x in station_list:\n",
    "        try:\n",
    "            dydf = dydf.append(QAQC_datapull('daily',x,yesterday,yesterday))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all daily data\\n')\n",
    "    \n",
    "    dydf = dydf.reset_index()\n",
    "    \n",
    "    #missing(dydf,f)\n",
    "   \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "        \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "         \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('-----------------------------\\n')\n",
    "    \n",
    "    rh_check(dydf,'rhmax',f)\n",
    "    rh_check(dydf,'rhmin',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    \n",
    "    sr_check(dydf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    \n",
    "    pp_check(dydf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(dydf,'st5mx',f)\n",
    "    soiltemp_check(dydf,'st5mn',f)\n",
    "\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    soiltemp_check(dydf,'st15mx',f)\n",
    "    soiltemp_check(dydf,'st5mx',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(dydf,'gust',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(dydf,f)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    QC_report_by_region(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = missing_check(QAQC_datapull('five_minute','bnv01',yesterday,today),'ws')\n",
    "len(test) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_accounted_for(df):\n",
    "    return len(df) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nothing_to_report(missing_check(QAQC_datapull('five_minute','bnv01',yesterday,today),'ws'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nothing_to_report(f):\n",
    "    f.write('Nothing to report!/n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
