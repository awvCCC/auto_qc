{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.now().strftime('%Y-%m-%d')\n",
    "yesterday = datetime.strftime(datetime.now() - timedelta(1), '%Y-%m-%d')\n",
    "month_year = datetime.now().strftime('%b-%Y')\n",
    "z = r'C:\\Users\\student\\Documents'\n",
    "file_date = datetime.strftime(datetime.now() - timedelta(1), '%m-%d-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = (r'C:\\Users\\student\\Documents\\QAQC_reports\\csv_vessel' + r'csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QAQC_datapull(a,b,c,d):\n",
    "    '''\n",
    "    Sends a data request to the CoAgMET server and processes the data into\n",
    "    an easy to read dataframe\n",
    "    \n",
    "    Arguments\n",
    "    - a = temporal frequency of the data \n",
    "        -must be entered as a string\n",
    "        -options:\n",
    "            -'five_minute'\n",
    "            -'hourly'\n",
    "            -'daily'\n",
    "    - b = a five character ID for one or more of the 87 CoAgMET stations\n",
    "        -must be entered as a string\n",
    "        -when calling data from multiple stations separate stations IDs\n",
    "        with a comma\n",
    "        -Station IDs can be found at https://coagmet.colostate.edu/station_index.php\n",
    "    - c = first day of the period from which you would like to request data\n",
    "        -must be entered as a string in 'yyyy-mm-dd' format\n",
    "    - d = last day of the period from which you would like to request data\n",
    "        -must be entered as a string in 'yyyy-mm-dd' format\n",
    "    '''\n",
    "    # Determines which set of elements to request depending on the data type\n",
    "    if a == 'hourly':\n",
    "        e = 'tmean,rh,vp,sr,ws,wind_vec,wind_std,pp,st5,st15,gust,gusttm,gustdir'\n",
    "        r = pd.date_range(start=c,end=d,freq='H')\n",
    "    elif a == 'five_minute':\n",
    "        e = 'tmean,rh,vp,sr,ws,wind_vec,wind_std,pp,st5,st15,gust,gusttm,gustdir'\n",
    "        r = pd.date_range(start=c,end=d,freq='5min')\n",
    "    elif a == 'daily':\n",
    "        e = ('tave,tmax,tmin,vp,rhmax,rhmin,sr,wrun,pp,' + \n",
    "        'st5mx,st5mn,st15mx,st15mn,gust,gustdir')\n",
    "        r = pd.date_range(start=c,end=d,freq='D')\n",
    "        \n",
    "    try:\n",
    "        # Makes the data request and loads the data into a csv\n",
    "        urllib.request.urlretrieve(\n",
    "            'http://coagmet.colostate.edu/cgi-bin/web_services.pl?' +\n",
    "            'type=' + a +\n",
    "            '&sids=' + b +\n",
    "            '&sdate=' + c +\n",
    "            '&edate=' + d +\n",
    "            '&elems=' + e,\n",
    "            filename=csv)\n",
    "    except Exception as e:\n",
    "        print('Something went wrong while pulling data from ' + \n",
    "              b + ': ' + e.args[0])\n",
    "    \n",
    "    \n",
    "    # Loads the data from the csv into a pandas DataFrame\n",
    "    data = pd.read_csv(csv)\n",
    "    data = data.reset_index()\n",
    "\n",
    "    # Converts the elements string into a list so they can be used \n",
    "    # as headers in the dataframe\n",
    "    headers = e.split(',')\n",
    "    # Adds to objects to the beginning of list for columns that are added by default\n",
    "    headers.insert(0,'date')\n",
    "    headers.insert(0,'station')\n",
    "    # Assigns the objects in the list as column headers in the dataframe\n",
    "    data.columns = headers\n",
    "    \n",
    "    # Instructs the computer to recognize values in the 'date' column are timestamps\n",
    "    data['date'] = pd.to_datetime(data.date)\n",
    "    \n",
    "    # Creates a datetime index depending on the temporal frequency\n",
    "    # of the data requested\n",
    "    if a == 'hourly':\n",
    "        r = pd.date_range(start=c,end=d,freq='H')\n",
    "    elif a == 'five_minute':\n",
    "        r = pd.date_range(start=c,end=d,freq='5min')\n",
    "    elif a == 'daily':\n",
    "        r = pd.date_range(start=c,end=d,freq='D')\n",
    "    \n",
    "    # Reindexes the CoAgMET data against the newly created datetime index to\n",
    "    # make it easier to account for missing data\n",
    "    data = data.set_index('date').reindex(r,copy=False).rename_axis('date')\n",
    "\n",
    "    # Ensures that all values in the 'station' column are correct\n",
    "    data['station'] = b\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report(x):\n",
    "    # Stores a path in which te report will be stored\n",
    "    y = x['path'] + r'\\_' + month_year\n",
    "    # Creates the pathway if it doesn't already exist\n",
    "    if not os.path.exists(y): os.makedirs(y)\n",
    "    # Creates a full name for the file that will be created    \n",
    "    file = (y + r'\\_' + file_date + '_' + x['drainage'] + \n",
    "            '_' + x['region'] + '_QAQC_report.txt')\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_check(df,x,f):    \n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df[x][n] > 46.1:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported a temperature of ' + str(df[x][n]) + \n",
    "                    '°C on ' + str(df['date'][n]) + \n",
    "                    '. If true, this a new state record for max temp.\\n')\n",
    "        elif df[x][n] < -51.7:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported a temperature of ' + str(df[x][n]) +\n",
    "                   '°C on ' + str(df['date'][n]) + \n",
    "                    '. If true, this a new state record for min temp.\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if(pd.isnull(df['tmean'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['rh'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing relative humidity data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['vp'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing vapor pressure data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['sr'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing solar radiation data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['ws'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing wind speed data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['wind_vec'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing wind direction data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['wind_std'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing wind direction standard deviation data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['pp'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing precipitation data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st5'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing 5cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st15'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing 15cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['gust'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing gust speed data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['gustdir'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing gust direction data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_missing(df,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if(pd.isnull(df['tave'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['tmax'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing maximum temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['tmin'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing minimum temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['rhmax'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing maximum relative humidity data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['rhmin'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing minimum relative humidity data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['vp'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing vapor pressure data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['sr'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing solar radiation data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['wrun'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing wind run data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['pp'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing precipitation data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st5mx'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing maximum 5cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st5mn'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing minimum 5cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st15mx'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing maximum 15cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['st15mn'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                   ' is missing minimum 15cm soil temperature data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['gust'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing gust speed data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif(pd.isnull(df['gustdir'][n])):\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' is missing gust direction data at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rh_check(df,x,f):\n",
    "        n = 0\n",
    "        for index,rows in df.iterrows():\n",
    "            if df[x][n] > 1.0:\n",
    "               return f.write(str(df['station'][n]) + \n",
    "                        ' reported a relative humidity of ' + str(df[x][n]) +\n",
    "                        ' at ' + str(df['date'][n]) + '\\n')\n",
    "            elif df[x][n] < 0.0:\n",
    "                return f.write(str(df['station'][n]) + \n",
    "                        ' reported negative relative humidity at ' +\n",
    "                       str(df['date'][n]) + '\\n')\n",
    "            elif df[x][n] < 0.01:\n",
    "                return f.write(str(df['date'][n]) + \n",
    "                        ' broke the world record for low relative humidity at ' + \n",
    "                       str(df['station'][n]) + '\\n')\n",
    "            n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sr_check(df,f):\n",
    "        n = 0\n",
    "        for index,rows in df.iterrows():\n",
    "            if df['sr'][n] < 0.0:\n",
    "               return  f.write(str(df['station'][n]) + \n",
    "                        ' reported negative solar radiation at ' + \n",
    "                        str(df['date'][n]) + '\\n')\n",
    "            n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ws_check(df,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df['ws'][n] < 0.0:\n",
    "           return f.write(str(df['station'][n]) + \n",
    "                    ' reported negative wind speed at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif df['ws'][0] > 77.785:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported a record breaking wind speed at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_check(df,f):\n",
    "    n = 0 \n",
    "    for index,rows in df.iterrows():\n",
    "        if df['wind_vec'][n] < 0.0:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported negative wind direction at ' +\n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp_check(df,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df['pp'][n] > 51.562:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported recording breaking amount of precip at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif df['pp'][n] < 0.0:\n",
    "            return f.write(str(df['station'][n]) + ' reported negative precip at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def st_check(df,x,f):\n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df[x][n] > 50.0:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported impossibly high 5cm soil temperature at ' +\n",
    "                   str(df['date'][n]) + '\\n')\n",
    "        elif df[x][n] < -15.0:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported impossibly low 5cm soil temperature at ' + \n",
    "                   str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gust_check(df,f):    \n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df['gust'][n] < 0.0:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported negative gust speed at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        elif df['gust'][n] > 77.785:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported a record breaking gust speed at ' + \n",
    "                    str(df['date'][n]) + '\\n')\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gustdir_check(df,f):    \n",
    "    n = 0\n",
    "    for index,rows in df.iterrows():\n",
    "        if df['gustdir'][n] < 0.0:\n",
    "            return f.write(str(df['station'][n]) + \n",
    "                    ' reported negative gust direction at ' + \n",
    "                    str(df['date'][n]) + '\\n' )\n",
    "        n = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A set of dictionaries for each region in the QAQC app\n",
    "Collegiate_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Collegiate_Valley'),\n",
    "    'stations':'bnv01,sld01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Collegiate_Valley'\n",
    "}\n",
    "East_Valley_Bottom = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\East_Valley_Bottom'),\n",
    "    'stations':'hly01,hly02,lam01,lam03,lam04,mcl01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'East_Valley_Bottom'\n",
    "}\n",
    "Mesas = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Mesas'),\n",
    "    'stations':'cnn01,hne01,pnr01,wcf01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Mesas'\n",
    "}\n",
    "North_of_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\North_of_Valley'),\n",
    "    'stations':'scm01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Mesas'\n",
    "}\n",
    "Plateau_South_of_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\Plateau_South_of_Valley'),\n",
    "    'stations':'wls01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'Plateau_South_of_Valley'\n",
    "}\n",
    "West_Valley_Bottom = {\n",
    "    'path':(z + r'\\QAQC_reports\\Arkansas_Drainage\\West_Valley_Bottom'),\n",
    "    'stations':'avn01,fwl01,ljt01,rfd01',\n",
    "    'drainage':'Arkansas',\n",
    "    'region':'West_Valley_Bottom'\n",
    "}\n",
    "Lower_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Lower_Valley'),\n",
    "    'stations':'cbl01,slt01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Lower_Valley'\n",
    "}\n",
    "Eagle_River_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Eagle_River_Valley'),\n",
    "    'stations':'egl01,gyp01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Eagle_River_Valley'\n",
    "}\n",
    "Four_Corners = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Four_Corners'),\n",
    "    'stations':'ctz01,dvc01,mnc01,twc01,yjk01,yuc01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Four_Corners'\n",
    "}\n",
    "Grand_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Grand_Valley'),\n",
    "    'stations':'cbn01,frt03,orm02',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Grand_Valley'\n",
    "}\n",
    "Headwaters = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Headwaters'),\n",
    "    'stations':'gby01,krm01,wfd01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Headwaters'\n",
    "}\n",
    "Lower_Gunnison = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Lower_Gunnison'),\n",
    "    'stations':'dlt01,ekt01,hot02,mtr01,oth01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Lower_Gunnison'\n",
    "}\n",
    "San_Juan = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\San_Juan'),\n",
    "    'stations':'drg01,ign01,kln01,pgs01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'San Juan'\n",
    "}\n",
    "San_Miguel_Paradox = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\San_Miguel_Paradox'),\n",
    "    'stations':'brk01,nwd01',\n",
    "    'drainage':'Colorado',\n",
    "    'region': r'San_Miguel_Paradox'\n",
    "}\n",
    "Upper_Gunnison = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Upper_Gunnison'),\n",
    "    'stations':'gun01',\n",
    "    'drainage':'Colorado',\n",
    "    'region':'Upper_Gunnison'\n",
    "}\n",
    "Yampa_White = {\n",
    "    'path':(z + r'\\QAQC_reports\\Colorado_Drainage\\Yampa_White'),\n",
    "    'stations':'clk01,hyd01,mkr01',\n",
    "    'drainage':'Colorado',\n",
    "    'region': 'Yampa_White'\n",
    "}\n",
    "North_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Kansas_Drainage\\North_Plains'),\n",
    "    'stations':'akr02,hxt01,hyk02,ilf01,pai01,stg01,wry02,yum02',\n",
    "    'drainage':'Kansas',\n",
    "    'region':'North_Plains'\n",
    "}\n",
    "South_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Kansas_Drainage\\South_Plains'),\n",
    "    'stations':'brl02,brl03,idl01,sbt01,stn01',\n",
    "    'drainage':'Kansas',\n",
    "    'region':'South_Plains'\n",
    "}\n",
    "Front_Range_Foothills = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\Front_Range_Foothills'),\n",
    "    'stations':'ckp01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'Front_Range_Foothills'\n",
    "}\n",
    "Lower_Plains = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\Lower_Plains'),\n",
    "    'stations':'brg01,hxt01,ksy01,ksy02',\n",
    "    'drainage':'Platte',\n",
    "    'region':'Lower_Plains'\n",
    "}\n",
    "North_Front_Range = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\North_Front_Range'),\n",
    "    'stations':'alt01,fcc01,fcl01,ftc01,ftc03,gly04,lcn01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'North_Front_Range'\n",
    "}\n",
    "North_Park = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\North_Park'),\n",
    "    'stations':'cow01,heb01,lar01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'North_Park'\n",
    "}\n",
    "South_Front_Range = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\South_Front_Range'),\n",
    "    'stations':'ccr01,cht01,eac01,ftl01,lsl01,pkh01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'South_Front_Range'\n",
    "}\n",
    "South_Park = {\n",
    "    'path':(z + r'\\QAQC_reports\\Platte_Drainage\\South_Park'),\n",
    "    'stations':'bnv01,jfn01,sld01',\n",
    "    'drainage':'Platte',\n",
    "    'region':'South_Park'\n",
    "}\n",
    "San_Luis_Valley = {\n",
    "    'path':(z + r'\\QAQC_reports\\Rio_Grande_Drainage\\San_Luis_Valley'),\n",
    "    'stations':'bla01,ctr01,ctr02,ljr01,san01',\n",
    "    'drainage':'Rio_Grande',\n",
    "    'region':'San_Luis_Valley'\n",
    "}\n",
    "\n",
    "\n",
    "region_list = [Collegiate_Valley,East_Valley_Bottom,Mesas,North_of_Valley,\n",
    "               Plateau_South_of_Valley,West_Valley_Bottom,Lower_Valley,\n",
    "               Eagle_River_Valley,Four_Corners,Grand_Valley,Headwaters,\n",
    "               Lower_Gunnison,San_Juan,San_Miguel_Paradox,Upper_Gunnison,\n",
    "               Yampa_White,North_Plains,South_Plains,Front_Range_Foothills,\n",
    "               Lower_Plains,North_Front_Range,North_Park,South_Front_Range,\n",
    "               South_Park,San_Luis_Valley]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QC_report_by_region(x):\n",
    "    '''\n",
    "    Runs through the previous days data each region of the QC and reports errors \n",
    "    into a text file\n",
    "    '''\n",
    "    file = create_report(x)\n",
    "    f = open(file,'w+')\n",
    "    \n",
    "    title = (yesterday + r' QA/QC Report for stations in the ' + x['region'] +\n",
    "            ' region of the ' + x['drainage'] + ' drainage\\n')\n",
    "    \n",
    "    f.write(title)\n",
    "    f.write('\\n')\n",
    "    \n",
    "    fmdf = pd.DataFrame()\n",
    "\n",
    "    station_list = x['stations'].split(',')\n",
    "    \n",
    "    f.write('Five Minute Data\\n')\n",
    "    f.write('------------------\\n')\n",
    "    f.write('Missing Data:\\n')\n",
    "    f.write('----------------\\n')\n",
    "\n",
    "    for x in station_list:\n",
    "        try:\n",
    "            fmdf = fmdf.append(QAQC_datapull('five_minute',x,yesterday,today))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all five minute data\\n')\n",
    "    \n",
    "    fmdf = fmdf.reset_index()\n",
    "            \n",
    "    missing(fmdf,f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "        \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "    \n",
    "    temp_check(fmdf,'tmean',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('------------------------------\\n')\n",
    "    \n",
    "    rh_check(fmdf,'rh',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    \n",
    "    sr_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    ws_check(fmdf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    vec_check(fmdf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    \n",
    "    pp_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    st_check(fmdf,'st5',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    st_check(fmdf,'st15',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(fmdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    hdf = pd.DataFrame()\n",
    "    \n",
    "    f.write('Hourly Data\\n')\n",
    "    f.write('------------\\n')\n",
    "    f.write('Missing data\\n')\n",
    "    f.write('------------\\n')\n",
    "    \n",
    "    for x in station_list:\n",
    "        try:\n",
    "            hdf = hdf.append(QAQC_datapull('hourly',x,yesterday,today))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all hourly data\\n')\n",
    "    \n",
    "    hdf = hdf.reset_index()\n",
    "\n",
    "    missing(hdf,f)\n",
    "\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "        \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "    \n",
    "    temp_check(hdf,'tmean',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('-----------------------------\\n')\n",
    "    \n",
    "    rh_check(hdf,'rh',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    sr_check(hdf,f)\n",
    "    sr_check(hdf,f)\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    ws_check(hdf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Wind Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    vec_check(hdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    pp_check(hdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    st_check(hdf,'st5',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    st_check(hdf,'st15',f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(hdf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(hdf,f)\n",
    "    \n",
    "    f.write('Daily Data\\n')\n",
    "    f.write('----------\\n')\n",
    "    f.write('Missing data:\\n')\n",
    "    f.write('-------------\\n')     \n",
    "    \n",
    "    dydf = pd.DataFrame()\n",
    "    \n",
    "    for x in station_list:\n",
    "        try:\n",
    "            dydf = dydf.append(QAQC_datapull('daily',x,yesterday,yesterday))\n",
    "        except ValueError:\n",
    "            f.write(x + ' is missing all daily data\\n')\n",
    "    \n",
    "    dydf = dydf.reset_index()\n",
    "    \n",
    "    daily_missing(dydf,f)\n",
    "   \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "        \n",
    "    f.write('Temperature Data Report\\n')\n",
    "    f.write('-----------------------\\n')\n",
    "    \n",
    "    temp_check(dydf,'tmax',f)\n",
    "    temp_check(dydf,'tmin',f)\n",
    "         \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Relative Humidity Data Report\\n')\n",
    "    f.write('-----------------------------\\n')\n",
    "    \n",
    "    rh_check(dydf,'rhmax',f)\n",
    "    rh_check(dydf,'rhmin',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Vapor Pressure Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Solar Radiation Data Report\\n')\n",
    "    f.write('---------------------------\\n')\n",
    "    \n",
    "    sr_check(dydf,f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Precipitation Data Report\\n')\n",
    "    f.write('-------------------------\\n')\n",
    "    \n",
    "    pp_check(dydf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('5cm Soil Temperature Data Report\\n')\n",
    "    f.write('--------------------------------\\n')\n",
    "    \n",
    "    st_check(dydf,'st5mx',f)\n",
    "    st_check(dydf,'st5mn',f)\n",
    "\n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('15cm Soil Temperature Data Report\\n')\n",
    "    f.write('---------------------------------\\n')\n",
    "    \n",
    "    st_check(dydf,'st15mx',f)\n",
    "    st_check(dydf,'st5mx',f)\n",
    "        \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Speed Data Report\\n')\n",
    "    f.write('----------------------\\n')\n",
    "    \n",
    "    gust_check(dydf,f)\n",
    "    \n",
    "    f.write('\\n')\n",
    "    f.write('\\n')\n",
    "    \n",
    "    f.write('Gust Direction Data Report\\n')\n",
    "    f.write('--------------------------\\n')\n",
    "    \n",
    "    gustdir_check(dydf,f)\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in region_list:\n",
    "    QC_report_by_region(region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
